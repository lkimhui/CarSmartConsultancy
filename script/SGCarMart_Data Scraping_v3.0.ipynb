{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7302c794",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "from bs4 import BeautifulSoup,\n",
    "import requests as req,\n",
    "import pickle,\n",
    "import re,\n",
    "import pandas as pd,\n",
    "import numpy as np,\n",
    "from io import BytesIO,\n",
    "from PIL import Image,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42fb87e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9da700",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(bs4.__version__)\n",
    "print(req.__version__)\n",
    "print(pd.__version__)\n",
    "print(np.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc11f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find a spefic href tag to identify the car id-dl \n",
    "def car_model_href(href):\n",
    "    return href and re.compile(r\"(^(info.php).*)\").search(href)\n",
    "\n",
    "# creating lists for records\n",
    "car_id_dl_map = {}\n",
    "id_list = []\n",
    "dl_list = []\n",
    "\n",
    "# loop through all pages in sgcarmart used car listing\n",
    "BRSR = 0\n",
    "RPG = 100\n",
    "for BRSR in range(0, 2000, 100): #100000\n",
    "      url = f\"https://www.sgcarmart.com/used_cars/listing.php?BRSR={BRSR}&RPG={RPG}\"\n",
    "      html_text = req.get(url)\n",
    "      soup = BeautifulSoup(html_text.content, \"lxml\")\n",
    "      listings = soup.body.find('div', {'class': 'listing_searchbar_position'}).p.string.replace(\" \", \"\")\n",
    "      cleaned_listings = re.sub(\"\\D\", '', listings)\n",
    "      listings_count = int(cleaned_listings)\n",
    "      # car models found per page\n",
    "      car_model_list = soup.body.find('div', {'id':'content'}).find('form', {'name':'searchform'}).next_sibling.next_sibling.find_all(href=car_model_href, string=True)\n",
    "      for model in car_model_list:\n",
    "          id = str(model).partition('ID')[2].partition('&')[0].partition('=')[-1]\n",
    "          dl = str(model).partition('DL')[2].partition('\"')[0].partition('=')[-1]\n",
    "          if id not in car_id_dl_map:\n",
    "              car_id_dl_map[id] = dl\n",
    "              id_list.append(id)\n",
    "              dl_list.append(dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be015b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions defined to scrape each features\n",
    "def get_model(soup):\n",
    "    model = soup.body.find('div', {'id':'contentblank'}).select('div:nth-of-type(2)')[0].select('div:nth-of-type(1)')[0].text.strip()\n",
    "    return model\n",
    "\n",
    "def get_price(soup):\n",
    "    pr = soup.body.find('div', {'id':'main_left'}).find('table', {'id':'carInfo'}).find('tr').find_all('strong')[1]\n",
    "    pr = str(pr).partition('/')[0].partition('>')[-1].partition('<')[0].strip()\n",
    "    return pr\n",
    "\n",
    "def get_depreciation(soup):\n",
    "    dep = soup.body.find('div', {'id':'main_left'}).find('table', {'id':'carInfo'}).select('tr:nth-of-type(2)')[0].select('td:nth-of-type(2)')[0].find_all(string=re.compile(\"$\"))\n",
    "    dep = dep[0].replace(\" \", \"\").strip().partition('/')[0]\n",
    "    return dep\n",
    "\n",
    "def get_registrationDate(soup):\n",
    "    regDate = soup.body.find('div', {'id':'main_left'}).find('table', {'id':'carInfo'}).select('tr:nth-of-type(2)')[0].select('td:nth-of-type(4)')[0].find_all(string=True)\n",
    "    reg = regDate[0].strip()\n",
    "    return reg\n",
    "\n",
    "def get_mileage(soup):\n",
    "    mi = soup.body.find('div', {'id':'main_left'}).find('table', {'id':'carInfo'}).select('tr:nth-of-type(3)')[0].select('div:nth-of-type(1)')[0].find('div', {'class':'row_info'}).string\n",
    "    mi = mi.strip()\n",
    "    return mi\n",
    "\n",
    "def get_roadTax(soup):\n",
    "    roadTax = soup.body.find('div', {'id':'main_left'}).find('table', {'id':'carInfo'}).select('tr:nth-of-type(3)')[0].find('td').select('div:nth-of-type(1)')[0].next_sibling.next_sibling.find('div', {'class':'row_info'}).string\n",
    "    roadTax = roadTax.strip()\n",
    "    return roadTax\n",
    "\n",
    "def get_deregistrationValue(soup):\n",
    "    dereg = soup.body.find('div', {'id':'main_left'}).find('table', {'id':'carInfo'}).select('tr:nth-of-type(3)')[0].find('td').select('div:nth-of-type(3)')[0].find('div', {'class':'row_info'}).find(string=re.compile(\"$\"))\n",
    "    dereg = dereg.partition(\"as\")[0].strip()\n",
    "    return dereg\n",
    "\n",
    "def get_coe(soup):\n",
    "    coe = soup.body.find('div', {'id':'main_left'}).find('table', {'id':'carInfo'}).select('tr:nth-of-type(3)')[0].find('td').select('div:nth-of-type(4)')[0].find('div', {'class':'row_info'}).string\n",
    "    coe = coe.strip()\n",
    "    return coe\n",
    "\n",
    "def get_engineCap(soup):\n",
    "    eng = soup.body.find('div', {'id':'main_left'}).find('table', {'id':'carInfo'}).select('tr:nth-of-type(3)')[0].find('td').select('div:nth-of-type(5)')[0].find('div', {'class':'row_info'}).string\n",
    "    eng = eng.strip()\n",
    "    return eng\n",
    "\n",
    "def get_curbWeight(soup):\n",
    "    weight = soup.body.find('div', {'id':'main_left'}).find('table', {'id':'carInfo'}).select('tr:nth-of-type(3)')[0].find('td').select('div:nth-of-type(6)')[0].find('div', {'class':'row_info'}).string\n",
    "    weight = weight.strip()\n",
    "    return weight\n",
    "\n",
    "def get_manufacturedYear(soup):\n",
    "    year = soup.body.find('div', {'id':'main_left'}).find('table', {'id':'carInfo'}).select('tr:nth-of-type(3)')[0].select('td:nth-of-type(2)')[0].select('div:nth-of-type(1)')[0].find('div', {'class':'row_info'}).string\n",
    "    year = year.strip()\n",
    "    return year\n",
    "\n",
    "def get_transmission(soup):\n",
    "    trans = soup.body.find('div', {'id':'main_left'}).find('table', {'id':'carInfo'}).select('tr:nth-of-type(3)')[0].select('td:nth-of-type(2)')[0].find('div', {'class':'eachInfo'}).next_sibling.next_sibling.find('div', {'class':'row_info'}).string\n",
    "    trans = trans.strip()\n",
    "    return trans\n",
    "\n",
    "def get_omv(soup):\n",
    "    tag = soup.body.find('div', {'id':'main_left'}).find('table', {'id':'carInfo'}).select('tr:nth-of-type(3)')[0].select('td:nth-of-type(2)')[0].select('div:nth-of-type(3)')[0].find('div', {'class':'row_title'}).text.strip()\n",
    "    if tag == 'OMV':\n",
    "        omv = soup.body.find('div', {'id':'main_left'}).find('table', {'id':'carInfo'}).select('tr:nth-of-type(3)')[0].select('td:nth-of-type(2)')[0].select('div:nth-of-type(3)')[0].find('div', {'class':'row_info'}).string\n",
    "        omv = omv.strip()\n",
    "    elif tag == 'Fuel Type':\n",
    "        omv = soup.body.find('div', {'id':'main_left'}).find('table', {'id':'carInfo'}).select('tr:nth-of-type(3)')[0].select('td:nth-of-type(2)')[0].select('div:nth-of-type(4)')[0].find('div', {'class':'row_info'}).string\n",
    "        omv = omv.strip()\n",
    "    else:\n",
    "        omv = 'NA'\n",
    "    return omv\n",
    "\n",
    "def get_arf(soup):\n",
    "    tag = soup.body.find('div', {'id':'main_left'}).find('table', {'id':'carInfo'}).select('tr:nth-of-type(3)')[0].select('td:nth-of-type(2)')[0].select('div:nth-of-type(4)')[0].find('div', {'class':'row_title'}).text.strip()\n",
    "    if tag == 'ARF':\n",
    "        arf = soup.body.find('div', {'id':'main_left'}).find('table', {'id':'carInfo'}).select('tr:nth-of-type(3)')[0].select('td:nth-of-type(2)')[0].select('div:nth-of-type(4)')[0].find('div', {'class':'row_info'}).string\n",
    "        arf = arf.strip()\n",
    "    elif tag == 'OMV':\n",
    "        arf = soup.body.find('div', {'id':'main_left'}).find('table', {'id':'carInfo'}).select('tr:nth-of-type(3)')[0].select('td:nth-of-type(2)')[0].select('div:nth-of-type(5)')[0].find('div', {'class':'row_info'}).string\n",
    "        arf = arf.strip()\n",
    "    else:\n",
    "        arf = 'NA'\n",
    "    return arf\n",
    "\n",
    "def get_power(soup):\n",
    "    tag = soup.body.find('div', {'id':'main_left'}).find('table', {'id':'carInfo'}).select('tr:nth-of-type(3)')[0].select('td:nth-of-type(2)')[0].select('div:nth-of-type(5)')[0].find('div', {'class':'row_title'}).text.strip()\n",
    "    if tag == 'Power':\n",
    "        power = soup.body.find('div', {'id':'main_left'}).find('table', {'id':'carInfo'}).select('tr:nth-of-type(3)')[0].select('td:nth-of-type(2)')[0].select('div:nth-of-type(5)')[0].find('div', {'class':'row_info'}).string\n",
    "        power = power.strip()\n",
    "    elif tag == 'ARF':\n",
    "        power = soup.body.find('div', {'id':'main_left'}).find('table', {'id':'carInfo'}).select('tr:nth-of-type(3)')[0].select('td:nth-of-type(2)')[0].select('div:nth-of-type(6)')[0].find('div', {'class':'row_info'}).string\n",
    "        power = power.strip()\n",
    "    else:\n",
    "        power = 'NA'\n",
    "    return power\n",
    "\n",
    "def get_number_of_owner(soup):\n",
    "    tag = soup.body.find('div', {'id':'main_left'}).find('table', {'id':'carInfo'}).select('tr:nth-of-type(3)')[0].select('td:nth-of-type(2)')[0].select('div:nth-of-type(6)')[0].find('div', {'class':'row_title'}).text.strip()\n",
    "    if tag == 'No. of Owners':\n",
    "        owner = soup.body.find('div', {'id':'main_left'}).find('table', {'id':'carInfo'}).select('tr:nth-of-type(3)')[0].select('td:nth-of-type(2)')[0].select('div:nth-of-type(6)')[0].find('div', {'class':'row_info'}).string\n",
    "        owner = owner.strip()\n",
    "    elif tag == 'Power':\n",
    "        owner = soup.body.find('div', {'id':'main_left'}).find('table', {'id':'carInfo'}).select('tr:nth-of-type(3)')[0].select('td:nth-of-type(2)')[0].select('div:nth-of-type(7)')[0].find('div', {'class':'row_info'}).string\n",
    "        owner = owner.strip()\n",
    "    else:\n",
    "        owner = 'NA'\n",
    "    return owner\n",
    "\n",
    "def get_type(soup):\n",
    "    try:\n",
    "        typ = soup.body.find('div', {'id':'main_left'}).find('table', {'id':'carInfo'}).select('tr:nth-of-type(4)')[0].find('a').text\n",
    "        typ = typ.strip()\n",
    "    except:\n",
    "        typ = soup.body.find('div', {'id':'main_left'}).find('table', {'id':'carInfo'}).select('tr:nth-of-type(3)')[0].find('td').select('div:nth-of-type(7)')[0].find('div', {'class':'row_info'}).text\n",
    "        typ = typ.strip()   \n",
    "    return typ\n",
    "\n",
    "def get_all_other_info(soup):\n",
    "    \n",
    "    # list of other info should return in this sequence [features, accessories, descriptions, category, status]\n",
    "    other_info = ['NA', 'NA', 'NA', 'NA', 'NA']\n",
    "    \n",
    "    # get the rows info\n",
    "    for i in range(5):\n",
    "        position = i + 5\n",
    "        row = soup.body.find('div', {'id':'main_left'}).find('table', {'id':'carInfo'}).select('tr:nth-of-type(%d)'%position)[0].find('td').text\n",
    "        cleaned_row = ' '.join([t for t in (row.replace('\\r', '').replace('\\n','').strip().split(\" \")) if len(t) > 0])\n",
    "        if (cleaned_row.split(\" \")[0] == 'Features'):\n",
    "            other_info[0] = cleaned_row\n",
    "        elif (cleaned_row.split(\" \")[0] == 'Accessories'):\n",
    "            other_info[1] = cleaned_row\n",
    "        elif (cleaned_row.split(\" \")[0] == 'Description'):\n",
    "            other_info[2] = cleaned_row\n",
    "        elif (cleaned_row.split(\" \")[0] == 'Category'):\n",
    "            other_info[3] = cleaned_row\n",
    "        elif (cleaned_row.split(\" \")[0] == 'Status'):\n",
    "            other_info[4] = cleaned_row\n",
    "            \n",
    "    # somehow category and status data might not be read in do continue with the following\n",
    "    if (other_info[1] == 'NA'):\n",
    "        cat = soup.body.find('div', {'id':'main_left'}).find('table', {'id':'carInfo'}).select('tr:nth-of-type(7)')[0].find('td').text\n",
    "        cleaned_cat = ' '.join([t for t in (cat.replace('\\r', '').replace('\\n','').replace('Status', '').strip().split(\" \")) if len(t) > 0])\n",
    "        other_info[3] = cleaned_cat\n",
    "        \n",
    "        stat = soup.body.find('div', {'id':'main_left'}).find('table', {'id':'carInfo'}).select('tr:nth-of-type(8)')[0].find('td').text\n",
    "        cleaned_stat = ' '.join([t for t in (stat.replace('\\r', '').replace('\\n','').replace('Status', '').strip().split(\" \")) if len(t) > 0])\n",
    "        other_info[4] = cleaned_stat\n",
    "    else:\n",
    "        cat = soup.body.find('div', {'id':'main_left'}).find('table', {'id':'carInfo'}).select('tr:nth-of-type(8)')[0].find('td').text\n",
    "        cleaned_cat = ' '.join([t for t in (cat.replace('\\r', '').replace('\\n','').replace('Status', '').strip().split(\" \")) if len(t) > 0])\n",
    "        other_info[3] = cleaned_cat\n",
    "        \n",
    "        stat = soup.body.find('div', {'id':'main_left'}).find('table', {'id':'carInfo'}).select('tr:nth-of-type(9)')[0].find('td').text\n",
    "        cleaned_stat = ' '.join([t for t in (stat.replace('\\r', '').replace('\\n','').replace('Status', '').strip().split(\" \")) if len(t) > 0])\n",
    "        other_info[4] = cleaned_stat\n",
    "        \n",
    "    return other_info\n",
    "\n",
    "def get_image(soup):\n",
    "    try:\n",
    "        image = soup.body.find('div', {'id':'contentblank'}).select('div:nth-of-type(2)')[0].select('div:nth-of-type(5)')[0].select('div:nth-of-type(1)')[0].next_sibling.next_sibling.findAll('img')[0].attrs['src']\n",
    "    except:\n",
    "        image = None\n",
    "        pass\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c1d0c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrape html data from text file\n",
    "# read a text file in format of .txt which contains html text\n",
    "def feature_scraping(filePath):\n",
    "\n",
    "    # read the file\n",
    "    with open(filePath, 'r') as file:\n",
    "        html_content = file.read()\n",
    "        \n",
    "    print(filePath)\n",
    "\n",
    "    # read the html content with BS4\n",
    "    soup = BeautifulSoup(html_content, 'lxml')\n",
    "\n",
    "    # scrape standard features\n",
    "    model = get_model(soup)\n",
    "    price = get_price(soup)\n",
    "    depreciation = get_depreciation(soup)\n",
    "    reg_date = get_registrationDate(soup)\n",
    "    manufactured_year = get_manufacturedYear(soup)\n",
    "    mileage = get_mileage(soup)\n",
    "    road_tax = get_roadTax(soup)\n",
    "    transmission = get_transmission(soup)\n",
    "    dereg_value = get_deregistrationValue(soup)\n",
    "    omv = get_omv(soup)\n",
    "    coe = get_coe(soup)\n",
    "    arf = get_arf(soup)\n",
    "    engine_cap = get_engineCap(soup)\n",
    "    power = get_power(soup)\n",
    "    curb_weight = get_curbWeight(soup)\n",
    "    number_of_owner = get_number_of_owner(soup)\n",
    "    types = get_type(soup)\n",
    "    images = get_image(soup)\n",
    "\n",
    "    # scrape other features\n",
    "    other_info  = get_all_other_info(soup)\n",
    "    features = other_info[0]\n",
    "    accessories = other_info[1]\n",
    "    descriptions = other_info[2]\n",
    "    category = other_info[3]\n",
    "    status = other_info[4]\n",
    "\n",
    "    # download the image to folder via the image link\n",
    "    # use pillow to read the btye string\n",
    "    response = req.get(images)\n",
    "    if response.status_code == 200:\n",
    "        img = Image.open(BytesIO(response.content))\n",
    "        img.save() # specific your full file diretory, including filename here\n",
    "\n",
    "    return model, price, depreciation, reg_date, manufactured_year, mileage, road_tax, transmission, dereg_value, omv, coe, arf, engine_cap, power, curb_weight, number_of_owner, types, features, accessories, descriptions, category, status, images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbcbca49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine the feature scraping function with the pathList\n",
    "# NOTE: do replace [path] in the map function with a list of file directory\\\n",
    "path = '/Users/eesoonhang/Downloads/test1.txt'\n",
    "%time sgCarMart_features = list(map(feature_scraping, [path]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32afa463",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform to dataframe\n",
    "df = pd.DataFrame(sgCarMart_features,\n",
    "                 columns = ['model', 'price', 'depreciation', 'registration_date', 'manufactured_year', 'mileage', 'road_tax', 'transmission', 'deregistration_value', 'omv', 'coe', 'arf', 'engine_cap', 'power', 'curb_weight', 'number_of_owner', 'types', 'features', 'accessories', 'descriptions', 'category', 'status'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be6bbe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = storage.Client()\n",
    "export_bucket = client.get_bucket(\"beadstore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9594e590",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write scrape data as csv into Google Cloud Storage\n",
    "df.to_csv()\n",
    "export_bucket.blob(\"sgcarmart_usedcar_info {0}.csv\".format(datetime.datetime.now()strftime('%Y-%m-%d %H_%M_%S'))).upload_from_string(df_all.to_csv(), 'text/csv')\n",
    "# df_all.to_csv('gs://beadstore/sgcarmart_usedcar_info/sgcarmart_usedcar_info.csv', index = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
